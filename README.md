
<!-- PROJECT LOGO -->
<br />
  <h1 align="center">Emojis Dataset</h1>

<p align="center">
  <!-- <a href="https://github.com/ymentha14/Emoji Dataset"> -->
   <p align="center">
    Human-generated emojis descriptions
  </p>
    <img src="images/emojis_header.png" alt="Logo" width="" height="">
  </a>

</p>



<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary><h2 style="display: inline-block">Table of Contents</h2></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#1-prerequisites">Prerequisites</a></li>
        <li><a href="#2-installation">Installation</a></li>
        <li><a href="#3-credentials-settings">Credentials Settings</a></li>
        <li><a href="#4-forms-generation">Forms Generation</a></li>
      </ul>
    </li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



## About the Project

As emojis became a central part of digital communication in the last decades, being able to represent these emojis in an appropriate semantic space  becomes a crucial aspect in Natural Language Processing to extract the meaning of a sentence.

Emojis Dataset consists of single-word descriptions of the 1325 most common emojis. This allows to represent emojis in the same feature space as word in any NLP model


* makes use of mt2gf
* specifications (30 etc)

## Dataset Specifications
*Each annotation consists of a human describing one emoji with one word*
* Language: English (US)
* Start Gathering Date: 09/12/20
* End Gathering Data: 12/12/20
* Total XXX Annotations
* Min XXX annotations/emoji
* Max XXX annotations/emoji
* Average XXX annotations/emoji
* Emojis present in the dataset:

```
#ï¸âƒ£*ï¸âƒ£Â©ï¸Â®ï¸â€¼ï¸â‰ï¸â„¢ï¸â„¹ï¸â†”ï¸â†•ï¸â†–ï¸â†—ï¸â†˜ï¸â†™ï¸â†©ï¸â†ªï¸âŒšâŒ›âŒ¨ï¸âï¸â©âªâ«â¬â­ï¸â®ï¸â¯ï¸â°â±ï¸â²ï¸â³â¸ï¸â¹ï¸âºï¸â“‚ï¸â–ªï¸â–«ï¸â–¶ï¸â—€ï¸â—»ï¸â—¼ï¸â—½â—¾â˜€ï¸â˜ï¸â˜‚ï¸â˜ƒï¸â˜„ï¸â˜ï¸â˜‘ï¸â˜”â˜•â˜˜ï¸â˜ï¸â˜ ï¸â˜¢ï¸â˜£ï¸â˜¦ï¸â˜ªï¸â˜®ï¸â˜¯ï¸â˜¸ï¸â˜¹ï¸â˜ºï¸â™ˆâ™‰â™Šâ™‹â™Œâ™â™â™â™â™‘â™’â™“â™Ÿï¸â™ ï¸â™£ï¸â™¥ï¸â™¦ï¸â™¨ï¸â™»ï¸â™¾ï¸â™¿âš’ï¸âš“âš”ï¸âš•ï¸âš–ï¸âš—ï¸âš™ï¸âš›ï¸âšœï¸âš ï¸âš¡âšªâš«âš°ï¸âš±ï¸âš½âš¾â›„â›…â›ˆï¸â›â›ï¸â›‘ï¸â›“ï¸â›”â›©ï¸â›ªâ›°ï¸â›±ï¸â›²â›³â›´ï¸â›µâ›·ï¸â›¸ï¸â›¹ï¸â›ºâ›½âœ‚ï¸âœ…âœˆï¸âœ‰ï¸âœŠâœ‹âœŒï¸âœï¸âœï¸âœ’ï¸âœ”ï¸âœ–ï¸âœï¸âœ¡ï¸âœ¨âœ³ï¸âœ´ï¸â„ï¸â‡ï¸âŒââ“â”â•â—â£ï¸â¤ï¸â•â–â—â¡ï¸â°â¿â¤´ï¸â¤µï¸â¬…ï¸â¬†ï¸â¬‡ï¸â¬›â¬œâ­â­•ã€°ï¸ã€½ï¸ãŠ—ï¸ãŠ™ï¸ğŸ€„ğŸƒğŸ…°ï¸ğŸ…±ï¸ğŸ…¾ï¸ğŸ…¿ï¸ğŸ†ğŸ†‘ğŸ†’ğŸ†“ğŸ†”ğŸ†•ğŸ†–ğŸ†—ğŸ†˜ğŸ†™ğŸ†šğŸˆğŸˆ‚ï¸ğŸˆšğŸˆ¯ğŸˆ²ğŸˆ³ğŸˆ´ğŸˆµğŸˆ¶ğŸˆ·ï¸ğŸˆ¸ğŸˆ¹ğŸˆºğŸ‰ğŸ‰‘ğŸŒ€ğŸŒğŸŒ‚ğŸŒƒğŸŒ„ğŸŒ…ğŸŒ†ğŸŒ‡ğŸŒˆğŸŒ‰ğŸŒŠğŸŒ‹ğŸŒŒğŸŒğŸŒğŸŒğŸŒğŸŒ‘ğŸŒ’ğŸŒ“ğŸŒ”ğŸŒ•ğŸŒ–ğŸŒ—ğŸŒ˜ğŸŒ™ğŸŒšğŸŒ›ğŸŒœğŸŒğŸŒğŸŒŸğŸŒ ğŸŒ¡ï¸ğŸŒ¤ï¸ğŸŒ¥ï¸ğŸŒ¦ï¸ğŸŒ§ï¸ğŸŒ¨ï¸ğŸŒ©ï¸ğŸŒªï¸ğŸŒ«ï¸ğŸŒ¬ï¸ğŸŒ­ğŸŒ®ğŸŒ¯ğŸŒ°ğŸŒ±ğŸŒ²ğŸŒ³ğŸŒ´ğŸŒµğŸŒ¶ï¸ğŸŒ·ğŸŒ¸ğŸŒ¹ğŸŒºğŸŒ»ğŸŒ¼ğŸŒ½ğŸŒ¾ğŸŒ¿ğŸ€ğŸğŸ‚ğŸƒğŸ„ğŸ…ğŸ†ğŸ‡ğŸˆğŸ‰ğŸŠğŸ‹ğŸŒğŸğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ”ğŸ•ğŸ–ğŸ—ğŸ˜ğŸ™ğŸšğŸ›ğŸœğŸğŸğŸŸğŸ ğŸ¡ğŸ¢ğŸ£ğŸ¤ğŸ¥ğŸ¦ğŸ§ğŸ¨ğŸ©ğŸªğŸ«ğŸ¬ğŸ­ğŸ®ğŸ¯ğŸ°ğŸ±ğŸ²ğŸ³ğŸ´ğŸµğŸ¶ğŸ·ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¼ğŸ½ï¸ğŸ¾ğŸ¿ğŸ€ğŸğŸ‚ğŸƒğŸ„ğŸ…ğŸ†ğŸ‡ğŸˆğŸ‰ğŸŠğŸ‹ğŸğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ–ï¸ğŸ—ï¸ğŸ™ï¸ğŸšï¸ğŸ›ï¸ğŸï¸ğŸŸï¸ğŸ ğŸ¡ğŸ¢ğŸ£ğŸ¤ğŸ¥ğŸ¦ğŸ§ğŸ¨ğŸ©ğŸªğŸ«ğŸ¬ğŸ­ğŸ®ğŸ¯ğŸ°ğŸ±ğŸ²ğŸ³ğŸ´ğŸµğŸ¶ğŸ·ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¼ğŸ½ğŸ¾ğŸ¿ğŸ€ğŸ‚ğŸƒğŸ„ğŸ…ğŸ†ğŸ‡ğŸˆğŸ‰ğŸŠğŸ‹ï¸ğŸŒï¸ğŸï¸ğŸï¸ğŸğŸğŸ‘ğŸ’ğŸ“ğŸ”ï¸ğŸ•ï¸ğŸ–ï¸ğŸ—ï¸ğŸ˜ï¸ğŸ™ï¸ğŸšï¸ğŸ›ï¸ğŸœï¸ğŸï¸ğŸï¸ğŸŸï¸ğŸ ğŸ¡ğŸ¢ğŸ£ğŸ¤ğŸ¥ğŸ¦ğŸ§ğŸ¨ğŸ©ğŸªğŸ«ğŸ¬ğŸ­ğŸ®ğŸ¯ğŸ°ğŸ³ï¸ğŸ³ï¸â€ğŸŒˆğŸ´â€â˜ ï¸ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ğŸ´ó §ó ¢ó ³ó £ó ´ó ¿ğŸ´ó §ó ¢ó ·ó ¬ó ³ó ¿ğŸµï¸ğŸ·ï¸ğŸ¸ğŸ¹ğŸºğŸ€ğŸğŸ‚ğŸƒğŸ„ğŸ…ğŸ†ğŸ‡ğŸˆğŸ‰ğŸŠğŸ‹ğŸŒğŸğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ”ğŸ•ğŸ•â€ğŸ¦ºğŸ–ğŸ—ğŸ˜ğŸ™ğŸšğŸ›ğŸœğŸğŸğŸŸğŸ ğŸ¡ğŸ¢ğŸ£ğŸ¤ğŸ¥ğŸ¦ğŸ§ğŸ¨ğŸ©ğŸªğŸ«ğŸ¬ğŸ­ğŸ®ğŸ¯ğŸ°ğŸ±ğŸ²ğŸ³ğŸ´ğŸµğŸ¶ğŸ·ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¼ğŸ½ğŸ¾ğŸ¿ï¸ğŸ‘€ğŸ‘ï¸ğŸ‘ï¸â€ğŸ—¨ğŸ‘‚ğŸ‘ƒğŸ‘„ğŸ‘…ğŸ‘†ğŸ‘‡ğŸ‘ˆğŸ‘‰ğŸ‘ŠğŸ‘‹ğŸ‘ŒğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘‘ğŸ‘’ğŸ‘“ğŸ‘”ğŸ‘•ğŸ‘–ğŸ‘—ğŸ‘˜ğŸ‘™ğŸ‘šğŸ‘›ğŸ‘œğŸ‘ğŸ‘ğŸ‘ŸğŸ‘ ğŸ‘¡ğŸ‘¢ğŸ‘£ğŸ‘¤ğŸ‘¥ğŸ‘¦ğŸ‘§ğŸ‘¨ğŸ‘¨â€âš•ï¸ğŸ‘¨â€âš–ï¸ğŸ‘¨â€âœˆï¸ğŸ‘¨â€â¤ï¸â€ğŸ‘¨ğŸ‘¨â€â¤ï¸â€ğŸ’‹â€ğŸ‘¨ğŸ‘¨â€ğŸŒ¾ğŸ‘¨â€ğŸ³ğŸ‘¨â€ğŸ“ğŸ‘¨â€ğŸ¤ğŸ‘¨â€ğŸ¨ğŸ‘¨â€ğŸ«ğŸ‘¨â€ğŸ­ğŸ‘¨â€ğŸ‘¦ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ğŸ‘¨â€ğŸ‘§ğŸ‘¨â€ğŸ‘§â€ğŸ‘¦ğŸ‘¨â€ğŸ‘§â€ğŸ‘§ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§â€ğŸ‘¦ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§â€ğŸ‘§ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ğŸ‘¨â€ğŸ’»ğŸ‘¨â€ğŸ’¼ğŸ‘¨â€ğŸ”§ğŸ‘¨â€ğŸ”¬ğŸ‘¨â€ğŸš€ğŸ‘¨â€ğŸš’ğŸ‘¨â€ğŸ¦¯ğŸ‘¨â€ğŸ¦°ğŸ‘¨â€ğŸ¦±ğŸ‘¨â€ğŸ¦²ğŸ‘¨â€ğŸ¦³ğŸ‘¨â€ğŸ¦¼ğŸ‘¨â€ğŸ¦½ğŸ‘©ğŸ‘©â€âš•ï¸ğŸ‘©â€âš–ï¸ğŸ‘©â€âœˆï¸ğŸ‘©â€â¤ï¸â€ğŸ‘¨ğŸ‘©â€â¤ï¸â€ğŸ‘©ğŸ‘©â€â¤ï¸â€ğŸ’‹â€ğŸ‘¨ğŸ‘©â€â¤ï¸â€ğŸ’‹â€ğŸ‘©ğŸ‘©â€ğŸŒ¾ğŸ‘©â€ğŸ³ğŸ‘©â€ğŸ“ğŸ‘©â€ğŸ¤ğŸ‘©â€ğŸ¨ğŸ‘©â€ğŸ«ğŸ‘©â€ğŸ­ğŸ‘©â€ğŸ‘¦ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ğŸ‘©â€ğŸ‘§ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘©â€ğŸ‘§â€ğŸ‘§ğŸ‘©â€ğŸ‘©â€ğŸ‘¦ğŸ‘©â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ğŸ‘©â€ğŸ‘©â€ğŸ‘§ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ğŸ‘©â€ğŸ’»ğŸ‘©â€ğŸ’¼ğŸ‘©â€ğŸ”§ğŸ‘©â€ğŸ”¬ğŸ‘©â€ğŸš€ğŸ‘©â€ğŸš’ğŸ‘©â€ğŸ¦¯ğŸ‘©â€ğŸ¦°ğŸ‘©â€ğŸ¦±ğŸ‘©â€ğŸ¦²ğŸ‘©â€ğŸ¦³ğŸ‘©â€ğŸ¦¼ğŸ‘©â€ğŸ¦½ğŸ‘ªğŸ‘«ğŸ‘¬ğŸ‘­ğŸ‘®ğŸ‘¯ğŸ‘°ğŸ‘±ğŸ‘²ğŸ‘³ğŸ‘´ğŸ‘µğŸ‘¶ğŸ‘·ğŸ‘¸ğŸ‘¹ğŸ‘ºğŸ‘»ğŸ‘¼ğŸ‘½ğŸ‘¾ğŸ‘¿ğŸ’€ğŸ’ğŸ’‚ğŸ’ƒğŸ’„ğŸ’…ğŸ’†ğŸ’‡ğŸ’ˆğŸ’‰ğŸ’ŠğŸ’‹ğŸ’ŒğŸ’ğŸ’ğŸ’ğŸ’ğŸ’‘ğŸ’’ğŸ’“ğŸ’”ğŸ’•ğŸ’–ğŸ’—ğŸ’˜ğŸ’™ğŸ’šğŸ’›ğŸ’œğŸ’ğŸ’ğŸ’ŸğŸ’ ğŸ’¡ğŸ’¢ğŸ’£ğŸ’¤ğŸ’¥ğŸ’¦ğŸ’§ğŸ’¨ğŸ’©ğŸ’ªğŸ’«ğŸ’¬ğŸ’­ğŸ’®ğŸ’¯ğŸ’°ğŸ’±ğŸ’²ğŸ’³ğŸ’´ğŸ’µğŸ’¶ğŸ’·ğŸ’¸ğŸ’¹ğŸ’ºğŸ’»ğŸ’¼ğŸ’½ğŸ’¾ğŸ’¿ğŸ“€ğŸ“ğŸ“‚ğŸ“ƒğŸ“„ğŸ“…ğŸ“†ğŸ“‡ğŸ“ˆğŸ“‰ğŸ“ŠğŸ“‹ğŸ“ŒğŸ“ğŸ“ğŸ“ğŸ“ğŸ“‘ğŸ“’ğŸ““ğŸ“”ğŸ“•ğŸ“–ğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“›ğŸ“œğŸ“ğŸ“ğŸ“ŸğŸ“ ğŸ“¡ğŸ“¢ğŸ“£ğŸ“¤ğŸ“¥ğŸ“¦ğŸ“§ğŸ“¨ğŸ“©ğŸ“ªğŸ“«ğŸ“¬ğŸ“­ğŸ“®ğŸ“¯ğŸ“°ğŸ“±ğŸ“²ğŸ“³ğŸ“´ğŸ“µğŸ“¶ğŸ“·ğŸ“¸ğŸ“¹ğŸ“ºğŸ“»ğŸ“¼ğŸ“½ï¸ğŸ“¿ğŸ”€ğŸ”ğŸ”‚ğŸ”ƒğŸ”„ğŸ”…ğŸ”†ğŸ”‡ğŸ”ˆğŸ”‰ğŸ”ŠğŸ”‹ğŸ”ŒğŸ”ğŸ”ğŸ”ğŸ”ğŸ”‘ğŸ”’ğŸ”“ğŸ””ğŸ”•ğŸ”–ğŸ”—ğŸ”˜ğŸ”™ğŸ”šğŸ”›ğŸ”œğŸ”ğŸ”ğŸ”ŸğŸ” ğŸ”¡ğŸ”¢ğŸ”£ğŸ”¤ğŸ”¥ğŸ”¦ğŸ”§ğŸ”¨ğŸ”©ğŸ”ªğŸ”«ğŸ”¬ğŸ”­ğŸ”®ğŸ”¯ğŸ”°ğŸ”±ğŸ”²ğŸ”³ğŸ”´ğŸ”µğŸ”¶ğŸ”·ğŸ”¸ğŸ”¹ğŸ”ºğŸ”»ğŸ”¼ğŸ”½ğŸ•‰ï¸ğŸ•Šï¸ğŸ•‹ğŸ•ŒğŸ•ğŸ•ğŸ•¯ï¸ğŸ•°ï¸ğŸ•³ï¸ğŸ•´ï¸ğŸ•µï¸ğŸ•¶ï¸ğŸ•·ï¸ğŸ•¸ï¸ğŸ•¹ï¸ğŸ•ºğŸ–‡ï¸ğŸ–Šï¸ğŸ–‹ï¸ğŸ–Œï¸ğŸ–ï¸ğŸ–ï¸ğŸ–•ğŸ––ğŸ–¤ğŸ–¥ï¸ğŸ–¨ï¸ğŸ–±ï¸ğŸ–²ï¸ğŸ–¼ï¸ğŸ—‚ï¸ğŸ—ƒï¸ğŸ—„ï¸ğŸ—‘ï¸ğŸ—’ï¸ğŸ—“ï¸ğŸ—œï¸ğŸ—ï¸ğŸ—ï¸ğŸ—¡ï¸ğŸ—£ï¸ğŸ—¨ï¸ğŸ—¯ï¸ğŸ—³ï¸ğŸ—ºï¸ğŸ—»ğŸ—¼ğŸ—½ğŸ—¾ğŸ—¿ğŸ˜€ğŸ˜ğŸ˜‚ğŸ˜ƒğŸ˜„ğŸ˜…ğŸ˜†ğŸ˜‡ğŸ˜ˆğŸ˜‰ğŸ˜ŠğŸ˜‹ğŸ˜ŒğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜‘ğŸ˜’ğŸ˜“ğŸ˜”ğŸ˜•ğŸ˜–ğŸ˜—ğŸ˜˜ğŸ˜™ğŸ˜šğŸ˜›ğŸ˜œğŸ˜ğŸ˜ğŸ˜ŸğŸ˜ ğŸ˜¡ğŸ˜¢ğŸ˜£ğŸ˜¤ğŸ˜¥ğŸ˜¦ğŸ˜§ğŸ˜¨ğŸ˜©ğŸ˜ªğŸ˜«ğŸ˜¬ğŸ˜­ğŸ˜®ğŸ˜¯ğŸ˜°ğŸ˜±ğŸ˜²ğŸ˜³ğŸ˜´ğŸ˜µğŸ˜¶ğŸ˜·ğŸ˜¸ğŸ˜¹ğŸ˜ºğŸ˜»ğŸ˜¼ğŸ˜½ğŸ˜¾ğŸ˜¿ğŸ™€ğŸ™ğŸ™‚ğŸ™ƒğŸ™„ğŸ™…ğŸ™†ğŸ™‡ğŸ™ˆğŸ™‰ğŸ™ŠğŸ™‹ğŸ™ŒğŸ™ğŸ™ğŸ™ğŸš€ğŸšğŸš‚ğŸšƒğŸš„ğŸš…ğŸš†ğŸš‡ğŸšˆğŸš‰ğŸšŠğŸš‹ğŸšŒğŸšğŸšğŸšğŸšğŸš‘ğŸš’ğŸš“ğŸš”ğŸš•ğŸš–ğŸš—ğŸš˜ğŸš™ğŸššğŸš›ğŸšœğŸšğŸšğŸšŸğŸš ğŸš¡ğŸš¢ğŸš£ğŸš¤ğŸš¥ğŸš¦ğŸš§ğŸš¨ğŸšªğŸš«ğŸš¬ğŸš­ğŸš®ğŸš¯ğŸš°ğŸš±ğŸš²ğŸš³ğŸš´ğŸšµğŸš¶ğŸš·ğŸš¸ğŸš¹ğŸšºğŸš»ğŸš¼ğŸš½ğŸš¾ğŸš¿ğŸ›€ğŸ›ğŸ›‚ğŸ›ƒğŸ›„ğŸ›…ğŸ›‹ï¸ğŸ›ŒğŸ›ï¸ğŸ›ï¸ğŸ›ï¸ğŸ›ğŸ›‘ğŸ›’ğŸ›•ğŸ› ï¸ğŸ›¡ï¸ğŸ›¢ï¸ğŸ›£ï¸ğŸ›¤ï¸ğŸ›¥ï¸ğŸ›©ï¸ğŸ›«ğŸ›¬ğŸ›°ï¸ğŸ›³ï¸ğŸ›´ğŸ›µğŸ›¶ğŸ›·ğŸ›¸ğŸ›¹ğŸ›ºğŸŸ ğŸŸ¡ğŸŸ¢ğŸŸ£ğŸŸ¤ğŸŸ¥ğŸŸ¦ğŸŸ§ğŸŸ¨ğŸŸ©ğŸŸªğŸŸ«ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤‘ğŸ¤’ğŸ¤“ğŸ¤”ğŸ¤•ğŸ¤–ğŸ¤—ğŸ¤˜ğŸ¤™ğŸ¤šğŸ¤›ğŸ¤œğŸ¤ğŸ¤ğŸ¤ŸğŸ¤ ğŸ¤¡ğŸ¤¢ğŸ¤£ğŸ¤¤ğŸ¤¥ğŸ¤¦ğŸ¤§ğŸ¤¨ğŸ¤©ğŸ¤ªğŸ¤«ğŸ¤¬ğŸ¤­ğŸ¤®ğŸ¤¯ğŸ¤°ğŸ¤±ğŸ¤²ğŸ¤³ğŸ¤´ğŸ¤µğŸ¤¶ğŸ¤·ğŸ¤¸ğŸ¤¹ğŸ¤ºğŸ¤¼ğŸ¤½ğŸ¤¾ğŸ¤¿ğŸ¥€ğŸ¥ğŸ¥‚ğŸ¥ƒğŸ¥„ğŸ¥…ğŸ¥‡ğŸ¥ˆğŸ¥‰ğŸ¥ŠğŸ¥‹ğŸ¥ŒğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥‘ğŸ¥’ğŸ¥“ğŸ¥”ğŸ¥•ğŸ¥–ğŸ¥—ğŸ¥˜ğŸ¥™ğŸ¥šğŸ¥›ğŸ¥œğŸ¥ğŸ¥ğŸ¥ŸğŸ¥ ğŸ¥¡ğŸ¥¢ğŸ¥£ğŸ¥¤ğŸ¥¥ğŸ¥¦ğŸ¥§ğŸ¥¨ğŸ¥©ğŸ¥ªğŸ¥«ğŸ¥¬ğŸ¥­ğŸ¥®ğŸ¥¯ğŸ¥°ğŸ¥±ğŸ¥³ğŸ¥´ğŸ¥µğŸ¥¶ğŸ¥ºğŸ¥»ğŸ¥¼ğŸ¥½ğŸ¥¾ğŸ¥¿ğŸ¦€ğŸ¦ğŸ¦‚ğŸ¦ƒğŸ¦„ğŸ¦…ğŸ¦†ğŸ¦‡ğŸ¦ˆğŸ¦‰ğŸ¦ŠğŸ¦‹ğŸ¦ŒğŸ¦ğŸ¦ğŸ¦ğŸ¦ğŸ¦‘ğŸ¦’ğŸ¦“ğŸ¦”ğŸ¦•ğŸ¦–ğŸ¦—ğŸ¦˜ğŸ¦™ğŸ¦šğŸ¦›ğŸ¦œğŸ¦ğŸ¦ğŸ¦ŸğŸ¦ ğŸ¦¡ğŸ¦¢ğŸ¦¥ğŸ¦¦ğŸ¦§ğŸ¦¨ğŸ¦©ğŸ¦ªğŸ¦®ğŸ¦¯ğŸ¦°ğŸ¦±ğŸ¦²ğŸ¦³ğŸ¦´ğŸ¦µğŸ¦¶ğŸ¦·ğŸ¦¸ğŸ¦¹ğŸ¦ºğŸ¦»ğŸ¦¼ğŸ¦½ğŸ¦¾ğŸ¦¿ğŸ§€ğŸ§ğŸ§‚ğŸ§ƒğŸ§„ğŸ§…ğŸ§†ğŸ§‡ğŸ§ˆğŸ§‰ğŸ§ŠğŸ§ğŸ§ğŸ§ğŸ§ğŸ§‘ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ§’ğŸ§“ğŸ§”ğŸ§•ğŸ§–ğŸ§—ğŸ§˜ğŸ§™ğŸ§šğŸ§›ğŸ§œğŸ§ğŸ§ğŸ§ŸğŸ§ ğŸ§¡ğŸ§¢ğŸ§£ğŸ§¤ğŸ§¥ğŸ§¦ğŸ§§ğŸ§¨ğŸ§©ğŸ§ªğŸ§«ğŸ§¬ğŸ§­ğŸ§®ğŸ§¯ğŸ§°ğŸ§±ğŸ§²ğŸ§³ğŸ§´ğŸ§µğŸ§¶ğŸ§·ğŸ§¸ğŸ§¹ğŸ§ºğŸ§»ğŸ§¼ğŸ§½ğŸ§¾ğŸ§¿ğŸ©°ğŸ©±ğŸ©²ğŸ©³ğŸ©¸ğŸ©¹ğŸ©ºğŸª€ğŸªğŸª‚ğŸªğŸª‘ğŸª’ğŸª“ğŸª”ğŸª•
```

## Getting Started
Emojis Dataset runs on docker. After having pulled the latest version of the project, run int the root of the repo:
```
make build_image
```
This will generate the docker image the project runs on: `emojis_dataset`

Once this is done, you need to export the following environment variables sp that the required folders are appropriately mounted (alternatively you can run `src .env` with the following `.env` file):

```
DATA_DIR=`pwd`/data
SRC_DIR=`pwd`/src
CREDS_DIR=`pwd`/creds
RESULTS_DIR=`pwd`/results
NOTEBOOKS_DIR=`pwd`/notebooks
WORD2VEC_DIR=`pwd`/emoji2vec/emoji2vec/data/word2vec
```

you can now simply start a container by running:
```
make run_container
```
The port 8888 is forwarded for jupyter notebooks and visualizations purpose. As the volumes are now mounted, every modification in the directories afformentioned will take effect on the host machine.

### Notebooks
```
make start_jupy
```
In order to access to the different part of data processing (cf Usage section) and forward a jupyter lab environment on local port 8888

### Dataset Generation
As the gathered raw data is stored in its original batch structure, you can generate the final format running
```
make dataset
```
and playing with the outlier detection parameters (repeating outliers/honeypot outliers).

The following files are available in the directory referred to by the `RESULTS_DIR` environment variable:

#### Dataset ( _`RESULTS_DIR/data/dataset`_ )
`emoji_dataset_prod.csv`: Output file containing the words used to describe the emojis presenting the following columns
  * **WorkerID**: mturk id of the worker
  * **FormId**: index of the form the emoji was part of (10 emojis/form)
  * **Duration**: time taken by the worker to complete the form
  * **emoji_index**: index of the current in the 1325-emojis indexing
  * **emoji**: string representation of the emoji (UTF-8)
  * **word**: word chosen by the worker to describe the emoji
#### Demographic Information


`workers_info_table.csv`: demographic information related to workers having completed the surveys. Presents the following columns
  * **WorkerID**: mturk id of the worker
  * **Age**: age of the worker
  * **Gender**: gender of the worker
  *  **Mothertongue**: mothertongue of the worker

In addition, you can recreate all the figures and embeddings referred in the report by running
```
python src/main.py
```
The results will once again be present in `RESULTS_DIR`. (takes ~10min to generate all embeddings.)

**NB**: Emojis Dataset uses the [Mturk2Gform](https://github.com/ymentha14/mturk2gform) package, which was itself developped in the context of this project.


Project Structure
------------


    .
    â”œâ”€â”€ creds
    â”‚   â”œâ”€â”€ aws.csv
    â”‚   â”œâ”€â”€ credentials.json
    â”‚   â”œâ”€â”€ creds
    â”‚   â””â”€â”€ token.pk
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ external
    â”‚   â”‚   â””â”€â”€ languages.csv
    â”‚   â”œâ”€â”€ mt2gf_cache
    â”‚   â”‚   â”œâ”€â”€ quality_check
    â”‚   â”‚   â””â”€â”€ watcher
    â”‚   â”œâ”€â”€ processed
    â”‚   â”‚   â””â”€â”€ dataset
    â”‚   â””â”€â”€ raw
    â”‚       â”œâ”€â”€ emojis_png
    â”‚       â”œâ”€â”€ forms
    â”‚       â””â”€â”€ tweets
    â”œâ”€â”€ dist <-- wheel for mt2gf
    â”‚   â”œâ”€â”€ mt2gf-0.1.0-py3-none-any.whl
    â”‚   â”œâ”€â”€ mt2gf-0.1.0.tar.gz
    â”‚   â””â”€â”€ mt2gf.whl
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ docs
    â”‚   â”œâ”€â”€ repor.pdf <-- report file
    â”œâ”€â”€ emoji2vec
    â”‚   â”œâ”€â”€ emoji2vec
    â”‚   â””â”€â”€ setup.py
    â”œâ”€â”€ env
    â”œâ”€â”€ images
    â”‚   â””â”€â”€ emojis_header.png
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ Makefile
    â”œâ”€â”€ notebooks
    â”‚   â”œâ”€â”€ 1_emojivec_EDA.ipynb
    â”‚   â”œâ”€â”€ 2_pilots_EDA.ipynb
    â”‚   â”œâ”€â”€ 3_selection.ipynb
    â”‚   â”œâ”€â”€ 4_distribution.ipynb
    â”‚   â”œâ”€â”€ 5_emoji2png.ipynb
    â”‚   â”œâ”€â”€ 6_forms_validation.ipynb
    â”‚   â”œâ”€â”€ 7_dataset_collection.ipynb
    â”‚   â””â”€â”€ 8_post_processing.ipynb
    â”œâ”€â”€ README.md
    â”œâ”€â”€ references
    â”‚   â””â”€â”€ emoji2vec.pdf
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ results
    â”‚   â”œâ”€â”€ emojivec_eda
    â”‚   â””â”€â”€ results
    â”œâ”€â”€ setup.py
    â””â”€â”€ src
        â”œâ”€â”€ analysis
        â”‚   â”œâ”€â”€ fraudulous.py
        â”‚   â””â”€â”€ postprocessing.py
        â”œâ”€â”€ collect
        â”‚   â”œâ”€â”€ appscript.js
        â”‚   â”œâ”€â”€ emoji2png.py
        â”‚   â”œâ”€â”€ forms_validation.py
        â”‚   â””â”€â”€ fraudulous.py
        â”œâ”€â”€ constants.py
        â”œâ”€â”€ exploration
        â”‚   â”œâ”€â”€ eda.py
        â”‚   â””â”€â”€ form10_eda.py
        â”œâ”€â”€ selection
        â”‚   â”œâ”€â”€ distribution.py
        â”‚   â””â”€â”€ selection.py
        â”œâ”€â”€ utils.py
        â””â”€â”€ visualization
            â”œâ”€â”€ __init__.py
            â””â”€â”€ tsne_viz.py
--------

## Usage
The Emojis Dataset project is divided in 8 parts: each of these parts has a respective commented notebook in the `notebooks` folder.



## License

Distributed under the MIT License. See `LICENSE` for more information.



## Contact
[Project Link](https://github.com/epfl-dlab/emojivec)

yann.mentha@gmail.com








<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/ymentha14/repo.svg?style=for-the-badge
[contributors-url]: https://github.com/ymentha14/repo/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/ymentha14/repo.svg?style=for-the-badge
[forks-url]: https://github.com/ymentha14/repo/network/members
[stars-shield]: https://img.shields.io/github/stars/ymentha14/repo.svg?style=for-the-badge
[stars-url]: https://github.com/ymentha14/repo/stargazers
[issues-shield]: https://img.shields.io/github/issues/ymentha14/repo.svg?style=for-the-badge
[issues-url]: https://github.com/ymentha14/repo/issues
[license-shield]: https://img.shields.io/github/license/ymentha14/repo.svg?style=for-the-badge
[license-url]: https://github.com/ymentha14/repo/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://linkedin.com/in/ymentha14
