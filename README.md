
<!-- PROJECT LOGO -->
<br />
  <h1 align="center">Emojis Dataset</h1>

<p align="center">
  <!-- <a href="https://github.com/ymentha14/Emoji Dataset"> -->
   <p align="center">
    Human-generated emojis descriptions
  </p>
    <img src="images/emojis_header.png" alt="Logo" width="" height="">
  </a>

</p>



<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary><h2 style="display: inline-block">Table of Contents</h2></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#1-prerequisites">Prerequisites</a></li>
        <li><a href="#2-installation">Installation</a></li>
        <li><a href="#3-credentials-settings">Credentials Settings</a></li>
        <li><a href="#4-forms-generation">Forms Generation</a></li>
      </ul>
    </li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



## About the Project

As emojis became a central part of digital communication in the last decades, being able to represent these emojis in an appropriate semantic space  becomes a crucial aspect in Natural Language Processing to extract the meaning of a sentence.

Emojis Dataset consists of single-word descriptions of the 1325 most common emojis. This allows to represent emojis in the same feature space as word in any NLP model


* makes use of mt2gf
* specifications (30 etc)

## Dataset Specifications
*Each annotation consists of a human describing one emoji with one word*
* Language: English (US)
* Start Gathering Date: 09/12/20
* End Gathering Data: 12/12/20
* Total XXX Annotations
* Min XXX annotations/emoji
* Max XXX annotations/emoji
* Average XXX annotations/emoji
* Emojis present in the dataset:

```
#️⃣*️⃣©️®️‼️⁉️™️ℹ️↔️↕️↖️↗️↘️↙️↩️↪️⌚⌛⌨️⏏️⏩⏪⏫⏬⏭️⏮️⏯️⏰⏱️⏲️⏳⏸️⏹️⏺️Ⓜ️▪️▫️▶️◀️◻️◼️◽◾☀️☁️☂️☃️☄️☎️☑️☔☕☘️☝️☠️☢️☣️☦️☪️☮️☯️☸️☹️☺️♈♉♊♋♌♍♎♏♐♑♒♓♟️♠️♣️♥️♦️♨️♻️♾️♿⚒️⚓⚔️⚕️⚖️⚗️⚙️⚛️⚜️⚠️⚡⚪⚫⚰️⚱️⚽⚾⛄⛅⛈️⛎⛏️⛑️⛓️⛔⛩️⛪⛰️⛱️⛲⛳⛴️⛵⛷️⛸️⛹️⛺⛽✂️✅✈️✉️✊✋✌️✍️✏️✒️✔️✖️✝️✡️✨✳️✴️❄️❇️❌❎❓❔❕❗❣️❤️➕➖➗➡️➰➿⤴️⤵️⬅️⬆️⬇️⬛⬜⭐⭕〰️〽️㊗️㊙️🀄🃏🅰️🅱️🅾️🅿️🆎🆑🆒🆓🆔🆕🆖🆗🆘🆙🆚🈁🈂️🈚🈯🈲🈳🈴🈵🈶🈷️🈸🈹🈺🉐🉑🌀🌁🌂🌃🌄🌅🌆🌇🌈🌉🌊🌋🌌🌍🌎🌏🌐🌑🌒🌓🌔🌕🌖🌗🌘🌙🌚🌛🌜🌝🌞🌟🌠🌡️🌤️🌥️🌦️🌧️🌨️🌩️🌪️🌫️🌬️🌭🌮🌯🌰🌱🌲🌳🌴🌵🌶️🌷🌸🌹🌺🌻🌼🌽🌾🌿🍀🍁🍂🍃🍄🍅🍆🍇🍈🍉🍊🍋🍌🍍🍎🍏🍐🍑🍒🍓🍔🍕🍖🍗🍘🍙🍚🍛🍜🍝🍞🍟🍠🍡🍢🍣🍤🍥🍦🍧🍨🍩🍪🍫🍬🍭🍮🍯🍰🍱🍲🍳🍴🍵🍶🍷🍸🍹🍺🍻🍼🍽️🍾🍿🎀🎁🎂🎃🎄🎅🎆🎇🎈🎉🎊🎋🎍🎎🎏🎐🎑🎒🎓🎖️🎗️🎙️🎚️🎛️🎞️🎟️🎠🎡🎢🎣🎤🎥🎦🎧🎨🎩🎪🎫🎬🎭🎮🎯🎰🎱🎲🎳🎴🎵🎶🎷🎸🎹🎺🎻🎼🎽🎾🎿🏀🏂🏃🏄🏅🏆🏇🏈🏉🏊🏋️🏌️🏍️🏎️🏏🏐🏑🏒🏓🏔️🏕️🏖️🏗️🏘️🏙️🏚️🏛️🏜️🏝️🏞️🏟️🏠🏡🏢🏣🏤🏥🏦🏧🏨🏩🏪🏫🏬🏭🏮🏯🏰🏳️🏳️‍🌈🏴‍☠️🏴󠁧󠁢󠁥󠁮󠁧󠁿🏴󠁧󠁢󠁳󠁣󠁴󠁿🏴󠁧󠁢󠁷󠁬󠁳󠁿🏵️🏷️🏸🏹🏺🐀🐁🐂🐃🐄🐅🐆🐇🐈🐉🐊🐋🐌🐍🐎🐏🐐🐑🐒🐓🐔🐕🐕‍🦺🐖🐗🐘🐙🐚🐛🐜🐝🐞🐟🐠🐡🐢🐣🐤🐥🐦🐧🐨🐩🐪🐫🐬🐭🐮🐯🐰🐱🐲🐳🐴🐵🐶🐷🐸🐹🐺🐻🐼🐽🐾🐿️👀👁️👁️‍🗨👂👃👄👅👆👇👈👉👊👋👌👍👎👏👐👑👒👓👔👕👖👗👘👙👚👛👜👝👞👟👠👡👢👣👤👥👦👧👨👨‍⚕️👨‍⚖️👨‍✈️👨‍❤️‍👨👨‍❤️‍💋‍👨👨‍🌾👨‍🍳👨‍🎓👨‍🎤👨‍🎨👨‍🏫👨‍🏭👨‍👦👨‍👦‍👦👨‍👧👨‍👧‍👦👨‍👧‍👧👨‍👨‍👦👨‍👨‍👦‍👦👨‍👨‍👧👨‍👨‍👧‍👦👨‍👨‍👧‍👧👨‍👩‍👦👨‍👩‍👦‍👦👨‍👩‍👧👨‍👩‍👧‍👦👨‍👩‍👧‍👧👨‍💻👨‍💼👨‍🔧👨‍🔬👨‍🚀👨‍🚒👨‍🦯👨‍🦰👨‍🦱👨‍🦲👨‍🦳👨‍🦼👨‍🦽👩👩‍⚕️👩‍⚖️👩‍✈️👩‍❤️‍👨👩‍❤️‍👩👩‍❤️‍💋‍👨👩‍❤️‍💋‍👩👩‍🌾👩‍🍳👩‍🎓👩‍🎤👩‍🎨👩‍🏫👩‍🏭👩‍👦👩‍👦‍👦👩‍👧👩‍👧‍👦👩‍👧‍👧👩‍👩‍👦👩‍👩‍👦‍👦👩‍👩‍👧👩‍👩‍👧‍👦👩‍👩‍👧‍👧👩‍💻👩‍💼👩‍🔧👩‍🔬👩‍🚀👩‍🚒👩‍🦯👩‍🦰👩‍🦱👩‍🦲👩‍🦳👩‍🦼👩‍🦽👪👫👬👭👮👯👰👱👲👳👴👵👶👷👸👹👺👻👼👽👾👿💀💁💂💃💄💅💆💇💈💉💊💋💌💍💎💏💐💑💒💓💔💕💖💗💘💙💚💛💜💝💞💟💠💡💢💣💤💥💦💧💨💩💪💫💬💭💮💯💰💱💲💳💴💵💶💷💸💹💺💻💼💽💾💿📀📁📂📃📄📅📆📇📈📉📊📋📌📍📎📏📐📑📒📓📔📕📖📗📘📙📚📛📜📝📞📟📠📡📢📣📤📥📦📧📨📩📪📫📬📭📮📯📰📱📲📳📴📵📶📷📸📹📺📻📼📽️📿🔀🔁🔂🔃🔄🔅🔆🔇🔈🔉🔊🔋🔌🔍🔎🔏🔐🔑🔒🔓🔔🔕🔖🔗🔘🔙🔚🔛🔜🔝🔞🔟🔠🔡🔢🔣🔤🔥🔦🔧🔨🔩🔪🔫🔬🔭🔮🔯🔰🔱🔲🔳🔴🔵🔶🔷🔸🔹🔺🔻🔼🔽🕉️🕊️🕋🕌🕍🕎🕯️🕰️🕳️🕴️🕵️🕶️🕷️🕸️🕹️🕺🖇️🖊️🖋️🖌️🖍️🖐️🖕🖖🖤🖥️🖨️🖱️🖲️🖼️🗂️🗃️🗄️🗑️🗒️🗓️🗜️🗝️🗞️🗡️🗣️🗨️🗯️🗳️🗺️🗻🗼🗽🗾🗿😀😁😂😃😄😅😆😇😈😉😊😋😌😍😎😏😐😑😒😓😔😕😖😗😘😙😚😛😜😝😞😟😠😡😢😣😤😥😦😧😨😩😪😫😬😭😮😯😰😱😲😳😴😵😶😷😸😹😺😻😼😽😾😿🙀🙁🙂🙃🙄🙅🙆🙇🙈🙉🙊🙋🙌🙍🙎🙏🚀🚁🚂🚃🚄🚅🚆🚇🚈🚉🚊🚋🚌🚍🚎🚏🚐🚑🚒🚓🚔🚕🚖🚗🚘🚙🚚🚛🚜🚝🚞🚟🚠🚡🚢🚣🚤🚥🚦🚧🚨🚪🚫🚬🚭🚮🚯🚰🚱🚲🚳🚴🚵🚶🚷🚸🚹🚺🚻🚼🚽🚾🚿🛀🛁🛂🛃🛄🛅🛋️🛌🛍️🛎️🛏️🛐🛑🛒🛕🛠️🛡️🛢️🛣️🛤️🛥️🛩️🛫🛬🛰️🛳️🛴🛵🛶🛷🛸🛹🛺🟠🟡🟢🟣🟤🟥🟦🟧🟨🟩🟪🟫🤍🤎🤏🤐🤑🤒🤓🤔🤕🤖🤗🤘🤙🤚🤛🤜🤝🤞🤟🤠🤡🤢🤣🤤🤥🤦🤧🤨🤩🤪🤫🤬🤭🤮🤯🤰🤱🤲🤳🤴🤵🤶🤷🤸🤹🤺🤼🤽🤾🤿🥀🥁🥂🥃🥄🥅🥇🥈🥉🥊🥋🥌🥍🥎🥏🥐🥑🥒🥓🥔🥕🥖🥗🥘🥙🥚🥛🥜🥝🥞🥟🥠🥡🥢🥣🥤🥥🥦🥧🥨🥩🥪🥫🥬🥭🥮🥯🥰🥱🥳🥴🥵🥶🥺🥻🥼🥽🥾🥿🦀🦁🦂🦃🦄🦅🦆🦇🦈🦉🦊🦋🦌🦍🦎🦏🦐🦑🦒🦓🦔🦕🦖🦗🦘🦙🦚🦛🦜🦝🦞🦟🦠🦡🦢🦥🦦🦧🦨🦩🦪🦮🦯🦰🦱🦲🦳🦴🦵🦶🦷🦸🦹🦺🦻🦼🦽🦾🦿🧀🧁🧂🧃🧄🧅🧆🧇🧈🧉🧊🧍🧎🧏🧐🧑🧑‍🤝‍🧑🧒🧓🧔🧕🧖🧗🧘🧙🧚🧛🧜🧝🧞🧟🧠🧡🧢🧣🧤🧥🧦🧧🧨🧩🧪🧫🧬🧭🧮🧯🧰🧱🧲🧳🧴🧵🧶🧷🧸🧹🧺🧻🧼🧽🧾🧿🩰🩱🩲🩳🩸🩹🩺🪀🪁🪂🪐🪑🪒🪓🪔🪕
```

## Getting Started
Emojis Dataset runs on docker. After having pulled the latest version of the project, run int the root of the repo:
```
make build_image
```
This will generate the docker image the project runs on: `emojis_dataset`

Once this is done, you need to export the following environment variables sp that the required folders are appropriately mounted (alternatively you can run `src .env` with the following `.env` file):

```
DATA_DIR=`pwd`/data
SRC_DIR=`pwd`/src
CREDS_DIR=`pwd`/creds
RESULTS_DIR=`pwd`/results
NOTEBOOKS_DIR=`pwd`/notebooks
WORD2VEC_DIR=`pwd`/emoji2vec/emoji2vec/data/word2vec
```

you can now simply start a container by running:
```
make run_container
```
The port 8888 is forwarded for jupyter notebooks and visualizations purpose. As the volumes are now mounted, every modification in the directories afformentioned will take effect on the host machine.

### Notebooks
```
make start_jupy
```
In order to access to the different part of data processing (cf Usage section) and forward a jupyter lab environment on local port 8888

### Dataset Generation
As the gathered raw data is stored in its original batch structure, you can generate the final format running
```
make dataset
```
and playing with the outlier detection parameters (repeating outliers/honeypot outliers). The generated dataset is available in the directory referred to by the`RESULTS_DIR` environment variable.

**NB**: Emojis Dataset uses the [Mturk2Gform](https://github.com/ymentha14/mturk2gform) package, which was itself developped in the context of this project.


## Usage
The Emojis Dataset project is divided in 8 parts: each of these parts has a respective commented notebook in the `notebooks` folder.


#### Google Credentials
You need to set up the Google [People API](https://developers.google.com/people/quickstart/python) associated with your Google Drive account to establish the link with Mturk2Gform: once you are done, you can save the `credentials.json` file.

Project Structure
------------


    .
    ├── creds
    │   ├── aws.csv
    │   ├── credentials.json
    │   ├── creds
    │   └── token.pk
    ├── data
    │   ├── external
    │   │   └── languages.csv
    │   ├── mt2gf_cache
    │   │   ├── quality_check
    │   │   └── watcher
    │   ├── processed
    │   │   └── dataset
    │   └── raw
    │       ├── emojis_png
    │       ├── forms
    │       └── tweets
    ├── dist
    │   ├── mt2gf-0.1.0-py3-none-any.whl
    │   ├── mt2gf-0.1.0.tar.gz
    │   └── mt2gf.whl
    ├── Dockerfile
    ├── docs
    │   ├── commands.rst
    │   ├── conf.py
    │   ├── getting-started.rst
    │   ├── index.rst
    │   ├── make.bat
    │   └── Makefile
    ├── emoji2vec
    │   ├── emoji2vec
    │   └── setup.py
    ├── env
    ├── images
    │   └── emojis_header.png
    ├── LICENSE
    ├── Makefile
    ├── notebooks
    │   ├── 1_emojivec_EDA.ipynb
    │   ├── 2_pilots_EDA.ipynb
    │   ├── 3_selection.ipynb
    │   ├── 4_distribution.ipynb
    │   ├── 5_emoji2png.ipynb
    │   ├── 6_forms_validation.ipynb
    │   ├── 7_dataset_collection.ipynb
    │   └── 8_post_processing.ipynb
    ├── README.md
    ├── references
    │   └── emoji2vec.pdf
    ├── requirements.txt
    ├── results
    │   ├── emojivec_eda
    │   └── results
    ├── setup.py
    └── src
        ├── analysis
        │   ├── fraudulous.py
        │   └── postprocessing.py
        ├── collect
        │   ├── appscript.js
        │   ├── emoji2png.py
        │   ├── forms_validation.py
        │   └── fraudulous.py
        ├── constants.py
        ├── exploration
        │   ├── eda.py
        │   └── form10_eda.py
        ├── selection
        │   ├── distribution.py
        │   └── selection.py
        ├── utils.py
        └── visualization
            ├── __init__.py
            └── tsne_viz.py


--------







<!-- CONTRIBUTING -->
## Contributing

Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request



<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE` for more information.



<!-- CONTACT -->
## Contact

Your Name  - yann.mentha@gmail.com

Project Link: [https://github.com/ymentha14/mturk2gform](https://github.com/ymentha14/mturk2gform)







<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/ymentha14/repo.svg?style=for-the-badge
[contributors-url]: https://github.com/ymentha14/repo/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/ymentha14/repo.svg?style=for-the-badge
[forks-url]: https://github.com/ymentha14/repo/network/members
[stars-shield]: https://img.shields.io/github/stars/ymentha14/repo.svg?style=for-the-badge
[stars-url]: https://github.com/ymentha14/repo/stargazers
[issues-shield]: https://img.shields.io/github/issues/ymentha14/repo.svg?style=for-the-badge
[issues-url]: https://github.com/ymentha14/repo/issues
[license-shield]: https://img.shields.io/github/license/ymentha14/repo.svg?style=for-the-badge
[license-url]: https://github.com/ymentha14/repo/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://linkedin.com/in/ymentha14
