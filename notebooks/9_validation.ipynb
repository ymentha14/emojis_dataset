{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import sklearn.manifold as man\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from emoji2vec.model import Emoji2Vec, ModelParams\n",
    "from emoji2vec.phrase2vec import Phrase2Vec\n",
    "from emoji2vec.utils import build_kb, get_examples_from_kb, generate_embeddings, get_metrics\n",
    "\n",
    "from src.constants import (E2V_MAPPING_PATH, EMOJI_2_TOP_INDEX_PATH,E2V_DATA_DIR,EXPORT_DIR,\n",
    "                           EMBEDDING_TRAINING_DATA_DIR,W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"../data/raw/e2v/training/\",sep=\"\\t\",header=None)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pk.load(open(EMOJI_2_TOP_INDEX_PATH,\"rb\"))\n",
    "\n",
    "ems = set(dic.keys())\n",
    "\n",
    "dataset_df = pd.read_csv(EXPORT_DIR.joinpath(\"data/dataset/emoji_dataset_prod.csv\"),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_df(dataset_df,ratios):\n",
    "    assert(sum(ratios) == 1)\n",
    "    grouped_df = dataset_df.groupby('emoji')\n",
    "    train = []\n",
    "    dev = []\n",
    "    test = []\n",
    "    for em in dataset_df['emoji'].unique():\n",
    "        df = grouped_df.get_group(em).sample(frac=1)\n",
    "        n = df.shape[0]\n",
    "        n1 = int(n * ratios[0])\n",
    "        n2 = int(n * (ratios[0] + ratios[1]))\n",
    "        train.append(df.iloc[:n1])\n",
    "        dev.append(df.iloc[n1:n2])\n",
    "        test.append(df.iloc[n2:])\n",
    "    train = pd.concat(train,axis=0)\n",
    "    dev = pd.concat(dev,axis=0)\n",
    "    test = pd.concat(test,axis=0)\n",
    "    return train,dev,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_e2v_format(df):\n",
    "    df = df.copy()\n",
    "    df['label'] = True\n",
    "    df = (df[['word','emoji','label']]\n",
    "          .reset_index(drop=True)\n",
    "          .sample(frac=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_df(df):\n",
    "    df_neg = df.copy()\n",
    "\n",
    "    emojis = set(df_neg['emoji'].unique())\n",
    "\n",
    "    em_vocs = df_neg.groupby('emoji')['word'].agg(lambda x: set(x)).to_dict()\n",
    "\n",
    "    tot_voc = set.union(*em_vocs.values())\n",
    "\n",
    "    neg_words = [np.random.choice(list(tot_voc - em_vocs[em]))\n",
    "                  for em in df_neg['emoji'] ]\n",
    "    df_neg['word'] = neg_words\n",
    "    df_neg['label'] = False\n",
    "    return df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test(dataset_df):\n",
    "    \"\"\"\n",
    "    Generate the dataframe associated to the right format to train\n",
    "    a w2v model on the emojis\n",
    "    \n",
    "    Args:\n",
    "        dataset_df (pd.df): dataframe in production format\n",
    "    \n",
    "    Return:\n",
    "        [pd.df]: train dataframe\n",
    "        [pd.df]: validation dataframe with neg sampling\n",
    "        [pd.df]: test dataframe with neg sampling\n",
    "    \"\"\"\n",
    "    ratios = (0.8,0.1,0.1)\n",
    "    train_df, dev_df, test_df = split_dataset_df(dataset_df,ratios)\n",
    "    \n",
    "    train_df = convert_to_e2v_format(train_df)\n",
    "    \n",
    "    dev_df = convert_to_e2v_format(dev_df)\n",
    "    dev_df_neg = get_neg_df(dev_df)\n",
    "    dev_df = (dev_df.append(dev_df_neg)\n",
    "                    .sample(frac=1))\n",
    "    \n",
    "    test_df = convert_to_e2v_format(test_df)\n",
    "    test_df_neg = get_neg_df(test_df)\n",
    "    test_df = (test_df.append(test_df_neg)\n",
    "                    .sample(frac=1))\n",
    "    \n",
    "    n_emojis = dataset_df['emoji'].unique().shape[0]\n",
    "    assert(train_df['emoji'].unique().shape[0] == n_emojis)\n",
    "    assert(test_df['emoji'].unique().shape[0] == n_emojis)\n",
    "    assert(dev_df_neg['emoji'].unique().shape[0] == n_emojis)\n",
    "\n",
    "\n",
    "    return train_df, dev_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = get_train_val_test(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(EMBEDDING_TRAINING_DATA_DIR.joinpath(\"train.txt\"),sep=\"\\t\",header=None,index=False)\n",
    "dev_df.to_csv(EMBEDDING_TRAINING_DATA_DIR.joinpath(\"dev.txt\"),sep=\"\\t\",header=None,index=False)\n",
    "test_df.to_csv(EMBEDDING_TRAINING_DATA_DIR.joinpath(\"test.txt\"),sep=\"\\t\",header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/unicode/k-300_pos-4_rat-1_ep-80_dr-1/emoji2vec.bin\n"
     ]
    }
   ],
   "source": [
    "export_dir = EXPORT_DIR.joinpath(\"data/embeddings\")\n",
    "export_dir.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "\n",
    "# We format the exported file to a train\n",
    "\n",
    "\n",
    "\n",
    "# Emojis Dataset\n",
    "word2vec_path = str(W2V_PATH)\n",
    "mapping_path = str(EMOJI_2_TOP_INDEX_PATH)\n",
    "data_dir = str(EMBEDDING_TRAINING_DATA_DIR)\n",
    "embeddings_file = str(export_dir.joinpath(\"em_dataset_embeddings.pk\"))\n",
    "\n",
    "# Emoji2vec\n",
    "word2vec_path = str(W2V_PATH)\n",
    "mapping_path = str(E2V_MAPPING_PATH)\n",
    "data_dir = str(E2V_DATA_DIR.joinpath(\"training/\"))\n",
    "embeddings_file = str(export_dir.joinpath(\"e2v_embeddings.pk\"))\n",
    "\n",
    "\n",
    "in_dim = 300   # Length of word2vec vectors\n",
    "out_dim = 300  # Desired dimension of output vectors\n",
    "pos_ex = 4\n",
    "neg_ratio = 1\n",
    "max_epochs = 40\n",
    "dropout = 0.0\n",
    "\n",
    "params = ModelParams(in_dim=in_dim, out_dim=out_dim, pos_ex=pos_ex, max_epochs=max_epochs,\n",
    "                    neg_ratio=neg_ratio, learning_rate=0.001, dropout=dropout, class_threshold=0.5)\n",
    "\n",
    "\n",
    "#ckpt_path = './results/unicode/k-300_pos-4_rat-1_ep-40_dr-1/model.ckpt'\n",
    "ckpt_path = './results/unicode/k-300_pos-4_rat-1_ep-80_dr-1/model.ckpt'\n",
    "\n",
    "e2v_path = \"./results/unicode/k-300_pos-4_rat-1_ep-80_dr-1/emoji2vec.bin\"\n",
    "# e2v_path = params.model_folder('unicode') + '/emoji2vec.bin'\n",
    "# Y.\n",
    "#ckpt_path = './results/model.ckpt'\n",
    "# e2v_path = \"pre-trained/emoji2vec.bin\"\n",
    "\n",
    "print(e2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not PosixPath",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-40505cd7b86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reading training data from: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_kb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2phr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2emoj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_kb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind2emoj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not PosixPath"
     ]
    }
   ],
   "source": [
    "print('reading training data from: ' + data_dir)\n",
    "train_kb, ind2phr, ind2emoj = build_kb(data_dir)\n",
    "\n",
    "pk.dump(ind2emoj, open(mapping_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
